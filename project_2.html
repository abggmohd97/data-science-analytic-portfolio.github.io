<!DOCTYPE HTML>
<!--
	Forty by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Project 1</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
				<!-- Note: The "styleN" class below should match that of the banner element. -->
					<header id="header" class="alt style2">
						<a href="index.html" class="logo"><strong>THE PORTFOLIO</strong> <span>by abggmohd97</span></a>
						<nav>
							<a href="#menu">Menu</a>
						</nav>
					</header>

				<!-- Menu -->
					<nav id="menu">
						<ul class="links">
							<li><a href="index.html">Home</a></li>
							<!-- <li><a href="landing.html">Landing</a></li> -->
							<li><a href="about me.html">About Me</a></li>
							<li><a href="project_1.html">Project 1</a></li>
							<!-- <li><a href="project_2.html">Project 2</a></li> -->
							<li><a href="project_3.html">Project 3</a></li>
							<!--<li><a href="elements.html">Elements</a></li>-->
						</ul>
						<ul class="actions stacked">
							<!--
							<li><a href="#" class="button primary fit">Get Started</a></li>
							<li><a href="#" class="button fit">Log In</a></li>
							-->
						</ul>
					</nav>

				<!-- Banner -->
				<!-- Note: The "styleN" class below should match that of the header element. -->
					<section id="banner" class="style1">
						<div class="inner">
							<span class="image">
								<img src="images/project2_image/fitsum.jpg" alt="" />
							</span>
							<header class="major">
								<h1>BellaBeat</h1>
							</header>
							<div class="content">
								<p>Data Analytic</p>
							</div>
						</div>
					</section>

				<!-- Main -->
					<div id="main">

						<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>The Scenario</h2>
									</header>
									<p>You are a junior data analyst working on the marketing analyst team at Bellabeat, a high-tech manufacturer of health-focused products for women. Bellabeat is a successful small company, but they have the potential to become a larger player in the  
										global smart device market. Urška Sršen, cofounder and Chief Creative Officer of Bellabeat, believes that analyzing smart device fitness data could help unlock new growth opportunities for the company. You have been asked to focus on one of Bellabeat’s 
										products and analyze smart device data to gain insight into how consumers are using their smart devices. The insights you discover will then help guide marketing strategy for the company. You will present your analysis to the Bellabeat executive team 
										along with your high-level recommendations for Bellabeat's marketing strategy.</p>
								</div>
							</section>
							<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>The Data</h2>
									</header>
									<p>All information about the data can be found by viewing the dataset used. In summary, Sršen, Bellabeat’s cofounder and Chief Creative Officer, knows that an analysis of available consumer data would reveal more opportunities for growth. By that she intructed to 
										analyze smart device usage data in order to gain insight into how consumers use non-Bellabeat smart devices. Sršen encourages to use public data that explores smart device users daily habits. She points you to a specific data set: 
										<a href="https://www.kaggle.com/datasets/arashnic/fitbit">FitBit Fitness Tracker Data</a> (CC0: Public Domain, dataset made available through <a href="https://www.kaggle.com/arashnic">Mobius</a>) from Kaggle. This data set contains personal fitness tracker 
										from thirty fitbit users. Thirty eligible Fitbit users consented to the submission of personal tracker data, including minute-level output for physical activity, heart rate, and sleep monitoring. It includes information about daily activity, steps, and heart rate 
										that can be used to explore users’ habits.
									</p>
								</div>
							</section>
							<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>The Tools Used</h2>
									</header>
									<p>All tools listed in this project, involved in exploring, cleaning, tranforming, arranging, visualizing all the dataset used. All tools are as follows:<br />
									<ul>
										<li><b>R Programming with RStudio</b></li><br />
										<li><b>Tableau</b></li>
									</ul>					
									</p>
								</div>
							</section>
							<!-- One -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Six Important Analytic Steps</h2>
									</header>
									<p>The Google Data Analytics Certificate program provides a six step data analysis process. This is the process that will be followed here. The six steps are as follows:<br /><br />

										1. <b>Ask</b><br /><br />
										2. <b>Prepare</b><br /><br />
										3. <b>Process</b><br /><br />
										4. <b>Analyze</b><br /><br />
										5. <b>Share</b><br /><br />
										6. <b>Act</b>
									
									</p>
								</div>
							</section>
							<!-- Ask -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Phase 1: Ask</h2>
									</header>
									<p>The objective of this step is to identify the key stakeholders in the project analysis, clearly define the business task, and ensure the problem in question is fully understood. 
										The step involves asking questions of the stakeholders to fully understand their needs before beginning the analysis. This is a case study are based on a real-world company, BellaBeat, the business 
										task is very clearly defined for us. In summary, the stakeholders would be the cofounder and Chief Creative Officer, Urška Sršen, who has assigned the task, Sando Mur, Mathematician and 
										Bellabeat’s cofounder and also a key member of the Bellabeat executive team and Bellabeat marketing analytics team, a team of data analysts responsible for collecting, analyzing, and reporting data 
										that helps guide Bellabeat’s marketing strategy.</a>
									</p>
								</div>
							</section>
							<!-- Prepare -->
							<section id="one" >
								<div class="inner">
									<header class="major">
										<h2>Phase 2: Prepare</h2>
									</header>
									<p>The objective of this step is to prepare data for the analysis. This begins by identifying the data that will be used -
										 is it already available, or will it need to be collected? Once the data is identified and obtained, it needs to be inspected. 
										This is done to ensure understanding of how the data is organized and structured.
										 The data (as well as the data source) must the be profiled to determine credibility - 
										 are there potential bias problems, are there any problems with the data's integrity, 
										 can it be used to effectively address the business task? The final objective of this step is to ensure the data is handled properly, 
										 abiding by any licensing, as well as privacy and security concerns. As to start, below show list of data set need to be download from
										Kaggle:</a>
									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p2.1.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 2.1: Source of Dataset</figcaption><br />
									</a>
									</section>
									<p>All expected data set that needed in this analysis need to be downloaded properly as intructed. Before downloading the data, make sure to properly do a quick observation, especilly on the name, category, type or topic
										of the data. This to ensure that, every data we are going to use are properly relatable to our analysis purposes and also of course to avoid creating outlier in our analysis. After downloading all desired data set to our 
										local storage, make sure to decide where to keep and stored the dataset in a correct manner. By compiling all the dataset into one single location, it's going to make our data easier to be access, and the most important is to
										avoided time consuming when finding it. To do that, simply create a folder in desired location in our local computer. Below show the example</a>
								   </p>
								   <section id="one" class="side" >
									
										<img src="images/project2_image/p2.2.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 2.2: Dataset Stored in Local Folder</figcaption><br />
										<!---
										<div class="sidebyside">
											<img src="images/project1_image/pro2.1.JPG" alt="" style="width:100%" />
											<figcaption>Figure 1.2: Dataset Stored in Local Folder</figcaption><br />
										</div>
										-->
										<!---
										<div class="sidebyside">
											<img src="images/project1_image/pro2.2.JPG" alt="" style="width:100%" />
											<figcaption>Figure 1.3: Dataset Stored in Cloud Storage</figcaption><br />
										</div>
										-->
										<!---
										<div class="sidebyside">
											<img src="images/pic08.jpg" alt="" style="width:100%" />
										</div>
									    --->
									
									</section>

									<!--
									<p>Before analyzing the data, it is important to perform some deeper profiling to get a better understanding of the data and its quirks as well as to check accuracy and validity. 
										As noted in the prepare step, a bike ride has several components that are tracked including the starting and ending locations and times, the bike type used, and the user type. 
										Each of these should be more closely inspected to get a good understanding of the data. There should be two user types - member and casual. This can be confirmed by 
										querying the unique values in the associated column 'member_casual'. As seen in the code below, there are in fact only two unique values.
								   </p>
							    	
									<section id="one" class="spotlights" >
									<a href="generic.html" class="image">
										<img src="images/project1_image/pro2.3.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 1.4: Clarify data specification</figcaption><br />
									</a>
									</section>
									-->
								</div>
							</section>


							<!-- Process -->
							<section id="one" >
								<div class="inner">
									<header class="major">
										<h2>Phase 3: Process</h2>
									</header>
									
									<p>The objective of the process stage is to choose and prepare tools as well as to process the data to make sure it is ready for analysis - 
										checking for errors, cleaning and transforming it. The tool of choice for this analysis is R, and the environment is already set up, so the tools are ready. 
										That leaves profiling and processing the data to identify and address any errors or other problems, as well as transforming the data into the necessary 
										format and structure.
									</p>
									<section id="one" class="spotlights" >
											<img src="images/project1_image/pro3.1.jpg" alt="" data-position="center center" style="width:100%" />
											<br />
										</a>
									</section><br /><br />


								<h4><li> IMPORTING DATA & INSTALLING R PACKAGES </li></h4><br />
								<ul>

									<p>To start with R, first we need to import all the data set that we want to use in for our analysis. Previously, we already downloaded and stored all important data set 
										from Kaggle into a folder in our local storage, now it's time to upload it all into RStudio for observation. Before importing all expected dataset, make sure that all
										data file are in .csv format. Below shows all process and R syntax used to import the data:
								   </p>
							    	
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p3.1.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.1: Importing data set codes</figcaption><br />
									</a>
									</section>

									<p> After that, to check whether the dataset is uploaded properly, at the top left side tab of the RStudio, we can see a list that displays all successfully imported data with their rows and column information. 
										Below show an example:
								   </p>
							    	
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p3.2.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.2: Imported Data Checking</figcaption><br />
									</a>
									</section>

									<p>Before analyzing the data, it is important to perform some deeper profiling to get a better understanding of the data and its quirks as well as to check accuracy and validity. 
										To start with, first, we need to install all related packages or libraries for our analysis. R packages are a collection of R functions, compiled code, and sample data. They are 
										stored under a directory called "library" in the R environment. By default, R already installs a set of general packages during installation but there are more packages to be 
										added later in the process. As in our case, adding extra packages or library allow us to add more useful function for our analysis. The example below shows the process: 
										
								   </p>
							    	
									<section id="one" class="spotlights" >
									
										<img src="images/project2_image/p3.3.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.3: Installing R packages</figcaption><br />
									
									</section>

									<p> 
										From image above, there is two phases of when assigning packages. In the first part (first red-box), we need to installed the packages which loaded from The Comprehensive R Archive Network (CRAN), 
										the official R packages repository, providing thousands of free R usable packages. The packages used for this project are: 
										<ul>
											<li><b>tidyverse</b></li>
											<li><b>lubridate</b></li>
											<li><b>janitor</b></li>
											<li><b>dplyr</b></li>
											<li><b>skimr</b></li>
											<li><b>stringr</b></li>
											<li><b>reshape2</b></li>
										</ul>
										Now, after deciding which packages we want to use for our analysis, to start installing the packages in R, we can simply use <i>install.package()</i> function. Then, for the second steps (second red-box), after successfully installed all expected 
										packages, use <i>library()</i> function to call each of the packages, so that every pacakges installed are available in our current programming session. 
									</p>
								</ul><br />
									
								<h4><li> DATA INSPECTION </li></h4><br />
								<ul>
									<p> 
										After we have finished with installing all required packages, it's time to inspect all the dataset used for this project. From packages we have installed in our enviroment earlier, there were various of function we can use to analyse the data. As to begin with, 
										we are using <i>head()</i> and <i>tail()</i> function. Image below show an example of the assigning process:
									</p>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/p3.4.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.4: head() and tail() functions</figcaption><br />
									</a>
									</section>

									<p> 
										<i>head()</i> function is use to return first 5 rows of the dataset by default, while <i>tail()</i> function use to return last 5 rows of the dataset by default. Both two functions <i>head()</i> and <i>tail()</i> are very useful to begin our investigation on the dataset, 
										especially if we want to figure out a very general information like, what kind of data we have here or maybe we want to know the name of column that are used in the dataset itself. As we run the functions, the result below appears:
									</p>
									<section id="one" class="side" >
										
											<div class="sidebyside">
												<img src="images/project2_image/head().JPG" alt="" style="width:100%" />
												<figcaption>Figure 3.5: <i>head()</i> function output</figcaption><br />
											</div>
											
											<div class="sidebyside">
												<img src="images/project2_image/tail().JPG" alt="" style="width:100%" />
												<figcaption>Figure 3.6: <i>tail()</i> function output</figcaption><br />
											</div>
											
											<!---
											<div class="sidebyside">
												<img src="images/pic08.jpg" alt="" style="width:100%" />
											</div>
											--->
										
										</section>


										<p> 
											Instead of manually counting the number of columns and rows using the previous function, We can use the <i>dim()</i> function to count it for us. Below shows the process and result:
										</p>
										<section id="one" class="spotlights" >
											<img src="images/project2_image/p3.6.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.7: <i>dim()</i> function</figcaption><br />
										
										</section>

										<section id="one" class="spotlights" >
											<img src="images/project2_image/dim().JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.8: <i>dim()</i> function output</figcaption><br />
										
										</section>

										<p> 
											Also, instead of manually finding and examining each of words from <i>head()</i> and <i>tail()</i> functions output to figure out column names, We can use a simple <i>colnames()</i> function to list all column names for us. 
											Below shows the process and result:
										</p>

										<section id="one" class="spotlights" >
											<img src="images/project2_image/p3.7.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.9: <i>colnames()</i> function</figcaption><br />
										
										</section>

										<section id="one" class="spotlights" >
											<img src="images/project2_image/colnames().JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.10: <i>colnames()</i> function output</figcaption><br />
										
										</section>

										<p> 
											Other than using <i>head()</i> and <i>tail()</i> functions, we can also use <i>str()</i> and <i>glimpse()</i> functions. <i>str()</i> and <i>glimpse()</i> function in R Language is used for compactly displaying the internal structure of a R object and also capable to display an internal structure of large lists which are nested. 
											It provides one liner output for the basic R rows letting the user know about the object and its constituents. <i>str()</i> and <i>glimpse()</i> are basically interchangeable. <i>str()</i> is part of base R, an embedded package that contains the basic R functions that have been around for a long time. While, to use <i>glimpse()</i> 
											function, we need to load dplyr or tidyverse first. Below shows example of the process:
										</p>
										<section id="one" class="spotlights" >
											<img src="images/project2_image/p3.5.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.11: <i>str()</i> & <i>glimpse()</i> functions</figcaption><br />
										</a>
										</section>

										<p> 
											Compare to <i>head()</i> and <i>tail()</i> functions, <i>str()</i> and <i>glimpse()</i> functions also display a similar structure as those two functions, but with a much simpler, easy-viewing format and informative result, as it also provides each data type used for every column in the dataset. All the output are shown in the image below
										</p>
										<section id="one" class="side" >
										
											<div class="sidebyside">
												<img src="images/project2_image/str().JPG" alt="" style="width:100%" />
												<figcaption>Figure 3.12: <i>str()</i> function output</figcaption><br />
											</div>
											
											<div class="sidebyside">
												<img src="images/project2_image/glimpse().JPG" alt="" style="width:100%" />
												<figcaption>Figure 3.13: <i>glimpse()</i> function output</figcaption><br />
											</div>
											
											<!---
											<div class="sidebyside">
												<img src="images/pic08.jpg" alt="" style="width:100%" />
											</div>
											--->
										</a>
										</section>
									</ul><br />
									<!---Process CLEANING---->

								<h4><li> HANDLING NULL VALUES </li></h4><br />
								<ul>

									<p>
										Now, after we finished examining the dataset, we can start our cleaning process by searching for null and missing values. Null values can specified as an empty or a missing data in columns or rows in every dataset. Without properly handle this kind of errors, it would defecting every conclusion we made during this analysis. 
										So by that, make sure to seriously analyze every possibilities within kind of problems. To find null values, we can use <i>is.null()</i> or <i>is.na()</i> function. In term definition,  <i>is.null()</i> function used to check if the particular R object contains any NA value or not. Below show codes of the process:
								   </p>

								    <section id="one" class="spotlights" >
										<img src="images/project2_image/p3.8.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.14: <i>is.na()</i> & <i>!is.na()</i> functions</figcaption><br />
									</section>

									<p>
										All codes above actually having a similar purposes but with an opposite output. On the first line <i>is.null()</i> function are use to creating a condition that intended to find if there is any null values within the dataset, while the second line code that written as !is.na() creating condtion that intended to fulfill condition, is there no null values in the dataset. 
										Since our dataset didn't have any null values, a boolean type, true or false values retrieve for both functions:
								   </p>
								   <section id="one" class="spotlights" >
										<img src="images/project2_image/isna()1.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.15: <i>is.na()</i> & <i>!is.na()</i> functions output</figcaption><br />
									</section>

									<p>
										So, since there is no null values found in every dataset during whole analysis, there is no need for null remover functions. As a alternative, here are list of several functions that we can use to appropriately handle null values if there is any obtained during the future analysis:
										<ul>
											<li><b> na.omit(df)</b> <i>#Eliminating missing values completely from the entire data frame</i></li>
											<li><b>na.omit(df$column_name)</b> <i>#Eliminating missing values completely from a particular column</i></li>
											<li><b>data[is.na(df)]<- values</b> <i>#Replacing the NA’s in the entire data frame with ‘values’s</i></li>
											<li><b>df$column_name[is.na(df$column_name)]<-values</b> <i>#Replacing the NA’s in a particular column with ‘values’s</i></li>
										</ul>
								   </p>
								</ul><br />  

								<h4><li> HANDLING DUPLICATE VALUES </li></h4><br />
								<ul>
									<p>
										After finished exploring all null values in the dataset, let's proceed with finding and removing all the duplicate values. A duplicate value can be describes as one in which all values in at least one row are identical to all of the values in another row.
										Again as a remainder, without properly handle this kind of errors, it could cause a serious problems in every conclusion we made during whole analysis. So by that, make sure to properly analyze every possibilities within this kind of problems. 
										Now, to find the duplicates values in the dataset, we can use these functions:
								   </p>

								   <section id="one" class="spotlights" >
									<img src="images/project2_image/p3.9.JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.16: <i>any(duplicated())</i> & <i>sum(duplicated())</i> functions</figcaption><br />
									</section>

									<p>
										As we can see, these two functions are also a type of function that lies within another function too.  The <i>duplicated()</i> function we are using here, is a built-in R function that determines which elements of a vector or data frame are duplicates of elements with smaller 
										subscripts and returns a logical vector indicating which elements (rows) are duplicates. <i>any()</i> function in R used to tell if there are ANY of the given search terms in our vector where it returns either TRUE or FALSE values. 
										Since there is no duplicate value found in the dataset, these values return:
								   </p>
								   <section id="one" class="spotlights" >
									<img src="images/project2_image/any()sum().JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.17: <i>any(duplicated())</i> & <i>sum(duplicated())</i> functions output</figcaption><br />
									</section>

									<p>
										For <i>daily_activity</i> dataset, there is no duplicate values found here during the analysis and of course no duplicate remover functions been used too. From that, we can take a look for another example using different dataset to show how to remove a duplicate values properly. From our whole analysis, 
										duplicate values only can be found in <i>sleepDay_merged</i> dataset. Using previous functions on <i>sleepDay_merged</i> dataset, these values are retrieve:
								   </p>
								   <section id="one" class="spotlights" >
									<img src="images/project2_image/any()sum()2.JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.18: <i>any(duplicated())</i> & <i>sum(duplicated())</i> functions alternated output</figcaption><br />
									</section>

									<p>
										From the output showed, there are three (3) duplicate values found in <i>sleepDay_merged</i> dataset. Now, to remove the duplicate values, we can use distinct() functions. distinct() function from dplyr package is use to remove duplicate rows and return only unique values in a data set. 
										Now, to begin with, first, to make our task easier, we can use forward pipe operator, <i>%>%.</i> A Pipes operator are an extremely useful tool or technique that allow us to express a sequence of multiple operations which can greatly simplify the code and make every operations more intuitive. 
										Below shows the example of whole process:
								   </p>
								   <section id="one" class="spotlights" >
									<img src="images/project2_image/p3.10.JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.19: Pipe operator & <i>distinct()</i> functions</figcaption><br />
									</section>
	
								   <p>
										From the codes above, we create a new variable called cleaned_sleepDay, to stored our newly updated sleepDay_merged dataset. In programming, a Variables can be describe as a containers that used for storing data values. Every new variable we created that applying a data frame, 
										will be stored as a new dataset in R. To check whether our function properly eliminating the duplicate values we wanted to, we can use dim() function, to retrive dataset rows and column information, then compare it to the original dataset we use. Below show example of process:
							  	   </p>

									<section id="one" class="spotlights" >
									<img src="images/project2_image/p3.11.JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.20: <i>dim()</i> functions</figcaption><br />
									</section>
									
									<section id="one" class="spotlights" >
									<img src="images/project2_image/dim()2.JPG" alt="" data-position="center center" style="width:100%" />
									<figcaption>Figure 3.21: <i>dim()</i> functions output</figcaption><br />
									</section>

								</ul><br />

								<h4><li> CLEANING NAMES </li></h4><br />
								<ul>
									<p>
										After finished removing all duplicate values in desired data set, now, let's cleaning the data to create a proper formating. With a proper formating, it allow us to create a better understanding and eliminated unexpected confusion when analysing our dataset. The most basic 
										cleaning we can start with is renaming. Several column in the dataset may have the name that unsuitable to be applied or probably a typo, as to solve that, rename that column with proper naming convention. In our case, applying daily_activity dataset as an example, there is no specific
										errors or typos founded for each column, but it need proper naming convention. To do that, we can use <i>clean_names()</i> functions. <i>clean_names()</i> functions use to cleans names of an object usually a data frame resulting names becoming unique and consist only of the _ character, numbers, and letters.  
										Below show codes example:
									</p>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/p3.12.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.22: <i>colnames()</i> functions</figcaption><br />
									</section>

									<p>
										To view the updated data set, we can use <i>colnames()</i> functions again. Below shows comparison between before and latest output:	
									</p>

								
									<section id="one" class="spotlights" >
										<img src="images/project2_image/oldcolnames.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.23: Before <i>colnames()</i> function output</figcaption><br />
									</section>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/newcolnames.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.24: After <i>colnames()</i> function output</figcaption><br />
									</section>

								</ul><br />


								<h4><li> CONVERTING DATA TYPE </li></h4><br />
								<ul>
									<p>
										Now, after we finished with renaming the dataset column, we can proceed with converting column with an unproper applied data type. From our previous codes, we can view every column data type using str() and glimpse() functions. From initial observation, we know that
										activity_date column from daily_activity data set did not appllied with an accurate data type. Below shows the issues:
									 
									</p>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/glimpse()2.jpg" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.25: Checking on data type using <i>glimpse()</i> function</figcaption><br />
									</section>

									<p>											
										From the output above, the activity_date column is using chr or character as it main data type, where it should be a date type. Without properly handle this kind of problems, the column showed could not applying an accurate functionalities. So to convert character to date data type, 
										we can use as.date() function. The as.date() function can be defined as a functions that used to convert between character representations and objects of class "Date" representing calendar dates. Below shows the process and result converting the data type:
									</p>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/p3.13.jpg" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.26: <i>as.date()</i> functions</figcaption><br />
									</section>

									<section id="one" class="spotlights" >
										<img src="images/project2_image/glimpse()3.jpg" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.27: after <i>as.date()</i> functions</figcaption><br />
									</section>
								</ul><br />

								<h4><li> ADDING NEW COLUMN </li></h4><br />
								<ul>

									<p>
										The next things to do is, if needed, we can create a new column with a new additional information into our data set. Creating a new column allow us to create a new perpectives within our data and able to help develop correlation between new data and existing data. 
										In our cleaned_daily_activity data set, we can add another additional column, weekday, providing information on day of event. There are three main functions involved during the process which are add_column(), weekdays() and rename() function. In the example, cleaned_daily_activity 
										dataset it used. Below shows all the codes:
									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p4.3.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.28: Adding column using <i>add_column()</i>, <i>weekdays()</i> and <i>rename()</i></figcaption><br />
									</section>

									<p>
										All the functions above are assigned into variable named, cleaned_daily_activity, which generally will overwrite our existing data set throughout the process. The add_column() functions is used to appends or adds one or more columns to an existing data.frame. 
										While, weekdays() is a function in R used to determine the weekday on a specific date passed to it as argument. Then, a rename() function in R can be defined as a functions that is used to rename the column names of a data frame, based on the older names. 
										After we executed all the codes, we can use glimpse() function to view the updated data set. Below shows the process and output:
									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p4.4.jpg" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.29: Checking on updated data type using <i>glimpse()</i> function</figcaption><br />
									</section>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/glimpse()4.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.30: <i>glimpse()</i> function output</figcaption><br />
									</section>

								</ul><br />

								
								<h4><li> GENERAL ANALYSIS </li></h4><br />
								<ul>
									<p>
										To begin, start this phase with a quick observation on how many people involved sharing their data for this analysis. This is important to ensure that every data is complete and accurate as mentioned by the provider. 
										To start we can use distinct() and count() function with pipe operator on id column. A count() function lets us quickly count the unique values of one or more variables. 
										Here we are using "cleaned_daily_activity" dataset as example. Below shows the process and the output:
									</p>
									<section id="one" class="spotlights" >
											<img src="images/project2_image/p4.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.31: <i>count()</i> function</figcaption><br />
										
									</section>

									<section id="one" class="spotlights" >
										
										<img src="images/project2_image/4.1out.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.32: <i>count()</i> function output</figcaption><br />
									
									</section>

									<p>
										As for your information, every number of recorded data are depending on each individual, which in our case here, it means that the amount of unique id in a certain dataset can be varied and not necessarily identical 
										with another dataset within a particular topic. From the observation above, there is 33 people with 33 unique id involved in this analysis, sharing their daily activities data collected by smart device they used. 
										Next, we also want to know, how many days that this data cover. To have a view on that, we can use similar codes as before but this time without a count() function to examine the activity_date column. Below shows the process and the output:
									</p>
									
									<section id="one" class="spotlights" >
											<img src="images/project2_image/p4.2.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.33: Counting days using <i>distinct()</i> function</figcaption><br />	
									</section>

									<section id="one" class="spotlights" >
											<img src="images/project2_image/4.2.1out.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.34: Counting days using <i>distinct()</i> function Output</figcaption><br />
									</section>

									<p>
										From the above output, we can clearly see that, the date is recorded by days. To count how many days recorded, we can add count() function in our previous codes. Below shows the process and the result:
									</p>

									<section id="one" class="spotlights" >
											<img src="images/project2_image/p4.2.2.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.35: Counting days using <i>distinct()</i> with <i>count()</i> function</figcaption><br />	
									</section>

									<section id="one" class="spotlights" >
											<img src="images/project2_image/4.2.2out.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.36: Counting days using <i>distinct()</i> with <i>count()</i> function output</figcaption><br />
									</section>

									<p>
										From the output above, there is 31 total amount of days recorded into the data set starting from 12 April 2016. From that, we can concluded that this data set only covered up user daily activities in range of one month only. 
										After analysing the whole data set, we found that, the total amount of days or duration applied are identical for whole data set in this project which is one month.
									</p>
								</ul><br />
								

								<h4><li> DESCRIPTIVE STATISTICAL ANALYSIS </li></h4><br />
								<ul>
									<p>
										Next, we can continue our analysis phase by creating an initial descriptive analysis. Descriptive analysis can helps to describe, show or summarize data points in
										 a constructive way such that patterns might emerge that fulfill every condition. Now, to create a summarization of data, we can use these functions:
										 <ul>
											<li><b>max(df$column_name)</b> <i> # Return the highest values from a particular column in a dataset</i></li>
											<li><b>min(df$column_name)</b> <i> # Return the lowest values from a particular column in a dataset</i></li>
											<li><b>median(df$column_name)</b> <i> # Return the median values from a particular column in a dataset</i></li>
											<li><b>mean(df$column_name)</b> <i> # Return the total average from a particular column in a dataset</i></li>
										</ul>
									</p>

									<p>
										 Now, let's use total_steps column from <i>cleaned_daily_activity</i> dataset for an example. Total steps in our case study is a total values of user walking pattern or steps, distinct by each of user unique id, recorded by a smart device for a duration of one month. 
										 Using above summarisation functions, it help us to analyse an initial calculation and a statistical values, gaining a brief perpectives, involving the average, median, highest and lowest values of the particular topic. 
										 Below show the real application of functions in R and output:
									</p>
									<section id="one" class="spotlights" >									
											<img src="images/project2_image/p4.5.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.37: <i>max()</i>, <i>min()</i>, <i>median()</i> and <i>mean()</i> function</figcaption><br />										
									</section>

									<section id="one" class="spotlights" >									
											<img src="images/project2_image/desana.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 3.38: <i>max()</i>, <i>min()</i>, <i>median()</i> and <i>mean()</i> function output</figcaption><br />										
									</section>

								</ul>

								<h4><li> COMBINING DATASET </li></h4><br />
								<ul>

									<p>
										The next things we can do is, if needed, we can combined a specific dataset with another dataset we want. Creating a new combined dataset allow us to create a wider perpectives within our data and able to help develop new correlation. 
										To start combining the dataset, first things to do is make sure both dataset we want to join in have some identical points. An identical point can be describe as a column that works as a connector between first data with the second dataset. Those column 
										usually contains an identical values, identical in total amount (by rows) within two dataset we wanted to combined. In our case, we want to combine this three splitted dataset which are hourly_calories, hourly_intensities and hourly_steps dataset, merge them as one 
										hourly_activity dataset, by column 'Id' and 'ActivityHour'. Below shows all command: 
									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/combine_hourly_code.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.39: <i>full_join()</i> function</figcaption><br />
									</section>

									<p>
										To combine two different data set, we can use full_join() function. A full_join() function can be describe as a function combined data that return all rows and all columns from both x and y where there are not matching values, returns NA for the one missing. 
										From above codes, we can see there is two part in combining the dataset. This is because, since we have three dataset needed to be combined, the process cannot be done straighly forward and need to splited. Which for part 1, it is used to create initial data combination for only first two of the data set that were chosen. 
										Then, after finished with that, proceed for next codes to combine the previously merged dataset with another remaining dataset.
										Instead of using full_join function, we can also use merge() function as an alternative too to fully combine the data set.
										Below shows the output for the first part and the final part of data combination:
									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p1combine.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.40: <i>full_join()</i> function output (part 1)</figcaption><br />
									</section>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/p2combine.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.41: <i>full_join()</i> function output (part 2)</figcaption><br />
									</section>

								</ul><br />

								<h4><li> EXPORTING DATA </li></h4><br />
								<ul>

									<p>
										Now let's proceed with exporting dataset. Every dataset that already been cleaned and manipulated properly can be considered to be export as a csv file. By exporting the data set to csv files format, we can use those files to proceed with visualization, especially when using an outsource software. Other than that, exporting also cosidered as a precaution steps, if unexpected thing happened during our whole analysis, by saving and storing all important data set into our local storage, 
										surely avoiding us from losing all the data we have cleaned and repeating all process once again. Below shows all codes we used to exported all data:

									</p>
									<section id="one" class="spotlights" >
										<img src="images/project2_image/exportdata.JPG" alt="" data-position="center center" style="width:100%" />
										<figcaption>Figure 3.42: Exporting Data Set as CSV</figcaption><br />
									</section>

									<p>
										From codes above, all the data that been exported wil be stored in assigned local path, <i>'C:\Users\asus\Desktop\BellaBeat Dataset\cleaned_csv'</i>. By assigning a specific path and folders on storing the files, we can organized all the data set proper manner and the most important is avoid time-consuming searching for unlocated files when we need it urgently.
									</p>


								</ul><br />

								<p>
									As a conclusion, all step-by-step processes from this phases (3) that were shown, also been repeated for the other remaining dataset used in this analysis. From the observation of the whole dataset we are using, 
									there are four main behaviours on how each user uses their smart device. First is by using the device to track their daily activity, which consists of recording data on the walking steps, distance traveled, active minutes 
									and also how many calories burnt per day. The second type of user used the device to collect and visualize their sleeping pattern. Then, the third type of user intended to use the device to count and monitored their heartbeat. 
									And last but not least, the fourth user used the device to calculate their BMI and also record their physical weight measurement. A specific explaination for mentioned data will be presented in the next phase of the analysis.
							   </p>

								
								</div>
							</section>

							<!-- Analyse -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Phase 4: Analyse</h2>
									</header>
									
									<p>
										In data analysis, analyse is the most important phase. In this step of the process, the data will be analyzed to uncover patterns and trends in our data to make data-driven decisions. 
										To visiualize the data, we can use tableau. Tableau can be described as a software or tools that allowed data analyst to visualize and exploring interesting trends to answers the objectives.
									</p>
							
									<p>
										To start importing the csv file, inside tableau front tab, click <i>'text file'</i>, then choose our desired csv file, which in our case.
										Before proceed with visualizing the dataset, make sure to check all the column of the data and what kind of data type that were applied for each column. 
										This to ensure that there is no missing data during our visualization phase, and also able to secure proper data type espcially for numbers, to ensure it 
										gives accurate calculation and correct graph reading for the data.
									</p>
					
									<br />

									
						
									<h4><li> DAILY ACTIVITY </li></h4><br />

									
									<ul>
										<h5>> CORRELATION BETWEEN TOTAL STEPS & DISTANCE</h5>
										<p>
											The main purposes during visualization phase is to explore, obtain some interesting trends for the data and the most important things is to answer the objectives for our analysis. 
											Every data column in every dataset are comparable to each other, using row (x) and column (y) shelves structure in Tableau.
											For the first part of visualization, cleaned daily_activity data set are use:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/vis1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.1: <i>cleaned_daily_activity</i> dataset</figcaption><br />										
										</section>

										<p>
											 To begin our visualization, We can create correlation between Total Steps and Distance as shown below:
											
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.2: Daily Activity visualization (1)</figcaption><br />										
										</section>

										<p>
											The figure above shows, a correlation between users' steps and distance traveled from the daily_activty data set. From the graph above, we can clearly see there was a constant increase in data reading following the trend line. A trend line can be defined as a line that is superimposed on a chart revealing the overall direction of the data 
											which is great for showing a correlation between the data. From the graph, we can conclude that, the data reading showed are a postive correlation and no obvious outlier spotted. A positive correlation is a relationship between two variables in which both variables move in the same direction. Therefore, when one variable increases as the other variable increases, 
											or one variable decreases while the other decreases. In conclusion, user steps are strongly correlated with distance, which gives, the higher the steps, the farthest the distance.
										</p><br />
									
									
										<h5>> CORRELATION BETWEEN TOTAL STEPS & DISTANCE</h5>

										<p>
											Next, let create another correlation but this time between total steps and distance with calories burnt. Created figure are shown below:: 
										</p>
									
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.2.jpg" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.3: Daily Activity visualization (2)</figcaption><br />											
										</section>

										<p>
											The above graph showed that there are two trend within one frame, which for the first one is a total step against calories and another one is distance against calories. As we can see here, can be observed that,
											both graph trends are almost identical. From the observation, both graph in the figure above, are showing a postive correlation between applied data . In conclusion, user steps and distance are strongly correlated with calories burnt, 
											which gives, the higher the steps and distance, the higher the calories burnt.
										</p><br />
									
									
										<h5>> AVERAGE STEPS & CALORIES BURNT WITHIN ONE MONTH </h5>
									
										<p>
											After that, let's explore trend involving an average steps and calories in duration of one month. Below shows created graph:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.3.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.4: Daily Activity visualization (3)</figcaption><br />										
										</section>

										<p>
											The chart showed comparison between average steps and average calories burnt in duration of one month. From the trends above, average user steps are slighly consistent in early of april and forward, then flopping drastically early of may. 
											From previous observation we made, we know that the total user steps are having a strong positive correlation with calories. So by that, in this comparison, we can see an almost identical data reading too. In conclusion, average step and calories burnt 
											are higher during an early times when the data recorded, but dropping when it almost reach one month. There are no specific reason we have found during this analysis. As to solve that, we can provide more data the see a proper trends reading.
										</p><br />
									
									
										<h5>> AVERAGE STEPS, DISTANCE AND CALORIES BURNT IN WEEKDAY </h5>

										<p>
											In this part, there are three graphs created. The first one is used to compare each user's average step filter by day of the week. Below show the first graph:
										</p>
						
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.5.jpg" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.5: Daily Activity visualization (4a)</figcaption><br />										
										</section>

										<p>
											From figure above, we can clearly see the differences on user average steps per day of the week. There is a blue color ranges applied for each bar reading to make things clear for us with the darker the colour, the higher the values. From the graph, total average steps are highest on saturday, 
											then followed by tuesday, monday, wednesday, friday, thursday and the lowest one, on sunday.										</p>

										<p>
											For the second graph, it is used to compare trend on user's average distances grouped by day of the week. Below show the second graph:
										</p>
						
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.4.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.6: Daily Activity visualization (4b)</figcaption><br />											
										</section>

										<p>
											Similar as before, there a blue color ranges use as an indicator for each bar chart reading to make things understandable. Since there was a strong correlation between steps and distance from our previous observation, then of course, the total average distance also having a similar trends as average steps 
											which gives, the highest values are on saturday then slowly decreases followed by tuesday, monday, wednesday, friday, thursday and the lowest one, sunday.
										</p>

										<p>
											Then, for the last graph use to compare user' calories burnt in weekday. Below show the created graph:
										</p>
						
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.6.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.7: Daily Activity visualization (4c)</figcaption><br />										
										</section>

										<p>
											From the figure above, again, blue colour was use as an indicator for our visualization. From the trends here, we can clearly describe that, calories burnt are not necessarily depend on how much steps or distance user had for each day. From those bar chart, user burnt their calories more on tuesday, with just small amount of difference with the second, 
											saturday, then followed by friday, monday, wednesday, sunday and lastly, thursday.
										</p><br />
									

									
										<h5>> USER TOTAL ACTIVE MINUTE AND DISTANCE TRENDS</h5>
			
										<p>
											Now, let's try to explore active minutes categories provided in the data set. From figure1.1, we can see there are four (4) type of active minute which are a sedentary, a moderate, a fairly and a very active minute. To start with, first, we need to tranform and manipulate existing data set we are using, which in our case, daily_activity. 
											By Tranforming and manipulating the data allowed us to create a new and wider perpective on data want at the same time also to gain more insight and reveal some beneficial information we may need.
											To do that, we need to going back to RStudio again. In R, there are several function we could use to manipulate all the data we want. Below shows the process and the output:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/p4.6.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.8: Codes for data manipulation</figcaption><br />										
										</section>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/meltbf.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.9: Before melt() function</figcaption><br />										
										</section>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/meltaf.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.10: After melt() function</figcaption><br />										
										</section>

										<p>
											From above output, there are two (2) type of result displayed, which the first one is before applying melt() function, and another one is after applying melt() function. A melt() function can be described as an in-built R function that enables us to reshape and elongate the data frames in a user-defined manner, organizes the data values in a long data frame format, instead of wide. 
											Now, to create visualization, export the file created to local storage then import to tableau. Below shows the graph created:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/activedistotaluser.jpg" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.11: Daily Activity visualization (5a)</figcaption><br />										
										</section>

										<p>
											From above graph, there are four (4) type of user distance categories. We can see that user travelled distance are slighly higher when they in light active distance followed by, very active distance, moderate distance and lastly, sedentary distance which is zero. 
											A light active distance can be describe as a user movement activity that usually consumed less amount energy, which an opposites behaviour for very active, which likely to consume highest amount of energy. So we can conlude that, most of the user are more likely to travelled further when they walking with a lowest energy consumed,, moderate distance when using highest amount of energy, 
											lowest distance when consumed moderate amount of energy and of course zero movement when in sedentary distance.

										</p>

										<p>
											Now, let's demonstrate another data manipulation on daily activity dataset but this time by only using melt() function, below show the process and the output:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/p4.7.jpg" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.12: Applying <i>melt()</i> functions</figcaption><br />										
										</section>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/melt2.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.13: Data Output</figcaption><br />										
										</section>

										<p>
											From above output, compared to original dataset in figure... , we can clearly see that there is no more categorical distance and minute arrange by column, but it applying a new data structure. From the column variable, we can see that, each of categorical data been arranged by row not by column anymore which allowing us to manipulated the data in different visual.
										</p>
										<p>
											Then, from the newly transformed dataset above, after been exported properly, using tableau, we created a graph on average total values for each categorical active distance group by weekday. Below shows created graph chart:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.8.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.14: Daily Activity visualization (5b)</figcaption><br />										
										</section>

										<p>
											From above bar chart, we can see categorical active distance are sort by day of the week. From the observation, user usually walking farthest in light active category, moderately in very active, lowest in moderately active, then zero for sedentary. Grouped by weekday, light active category are at peak on saturday, while for very active, is highest during wednesday and moderate category is on saturday too. 
											In conclusion, we can confidently know that, user are more often achives higher walking distance when consumed lower amount of energy, while moderate distance when in very active, highest energy used and lowest distance in moderately active.
										</p>
										<p>
											Next, applying similar dataset as before, let's created another bar chart but this time on average total values for each categorical active minute group by weekday. Below shows created graph chart:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.7.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.15: Daily Activity visualization (5c)</figcaption><br />										
										</section>

										<p>
											From above bar chart, we can clearly see that each of categorical active minute are grouped by weekday, similar as previous graph. From the trends, we can clearly see that, most of the smart device user are more likely to spend most of their time on sedentary mode or in other word spending much time seated somewhat inactive then followed by lightly active minutes, very active minutes and the last one, fairly active minutes. 
											User are spending most of their sedentary minutes on monday and the lowest is on thursday. For lightly active minutes, it more likely to be highest on saturday and the lowest one on sunday. Then for moderately active minute it is on the peak on saturday and for very active minute, the highest is on tuesday. In conclusion, most of the user spending most of their time in a day in an sedentary mode, while the rest is active activity.
											As we can see, there are slighly a huge gaps between sedentary minute and active minute in the graph shown. Also can be seen that, from the bar readings trends, especially for very active and fairly active minute, the result are almost identical and no crucial difference between the data
										</p><br />

										
								
										<h5>> AVERAGE TOTAL STEPS, CALORIES AND INTESITIES TRENDS IN 48HR</h5>
										<p>
											Now let's proceed by using our previously combined dataset, cleaned_hourly_activity. This dataset contains all activity such as total steps, calories burnt, activity intensities which hourly recorded for the duration of one month. From that, we create another graph on average steps, calories and intensities within 48hr. Below shows the graph created:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.9.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.16: Daily Activity visualization (6)</figcaption><br />										
										</section>

										<p>
											From the graph above, we can clearly demonstrate, how each of the users in this dataset uses their smart device hourly a day. From what we can see here, there is an almost identical data reading trends between three applied variables which are user steps, calories, and intensities. From the line trends, user activities are at their lowest in the early morning, then have a continually increases starting at the dawn, 
											goes up until peak in the middle of the day, and finally to slowly decreases again from evening to the night. Since we are applying for 48hr, we can see that all the trends are repeated the same for the next day. From the observation we made, we can ensure that most of the user having a normal schedule for whole days and there is no unusual event spotted from the analysis
										</p><br />


										<h5>> CATEGORIZE USER BY ACTIVE, MODERATE AND LIGHT</h5>
										<p>
											Now, let's create another visualization on the user which we will categorize them by their activeness when using the smart device. But first, to do that, we need to manipulate and tranform our existing data as before. For this part we will tranforming daily_activity dataset. Below shows the process:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/p4.8.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.17: Codes</figcaption><br />										
										</section>

										<p>
											From the above codes, there is two part of process. For the first one we created codes to count the user id. By counting the id, we able to know how many data been updated by the user per day. So whenever the total values is equal to 31, its means it is equal to 31 days. Below show the output for the first code:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/count_id.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.18: Output (part 1)</figcaption><br />										
										</section>
										<p>
											Then for the second codes, it is used to categorize each of the counted id by the total values condition which in our case, whenever the values are more than 21, it will considered active. While when the values is in between 11 and 20, it will be considered moderately active and when ever the values is lower than 10, it considered as lightly active. 
											Below shows the output of the second codes:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/categorize_id.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.19: Output (part 2)</figcaption><br />										
										</section>
										<p>
											From the output above, whenever the id fullfill the condition mentioned in our previous codes, it will wrote as value 1. So now, after we finished with all data tranformation we need, let's continue upload the data to tableau to start visualization. In tableau we are going to use pie chart as our visualization component. Below shows the pie chart created:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/1.10.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.20: Daily Activity visualization (7)</figcaption><br />										
										</section>
										<p>
											From pie chart created above, we can see that, it is splited with three colours, blue, red and orange. Each of the colour are assigned for each catagories we created previously, blue for active user, red for moderate user and orange for light or least active user. From our initial observation, we can see that active segment are the highest among others, followed by moderate in second and then light colour the lowest. 
											In conclusion, among 33 total amount of users, most of them are actively record their the data on their daily activities with total population of 87.88%, followed by moderately-active user with 9.09% of total user and lastly, 3.03 % for lightly-active user. 
											
										</p><br />
										
									
									</ul>



									<h4><li> SLEEPING TRENDS </li></h4><br />

									
									<ul>
										
										<p>
											The main purposes during visualization phase is to explore, obtain some interesting trends for the data and the most important things is to answer the objectives for our analysis. 
											Every data column in every dataset are comparable to each other, using row (x) and column (y) shelves structure in Tableau.
											For the second part of visualization, cleaned sleep day data set are used as shown below:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/vis2.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.21: <i>cleaned_day_sleep</i> dataset</figcaption><br />									
										</section>

										<h5>> CORRELATION BETWEEN TOTAL TIMES IN BED AND MINUTE SLEEP</h5>

										<p>
											 To begin our visualization, We can create correlation between total times in bed and minute sleep as shown below:
											
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/2.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.22: Sleep Trends visualization (1)</figcaption><br />										
										</section>

										<p>
											The figure above shows, a correlation between users' total times in bed and minute sleep from the sleep_day data set. From the graph above, we can see that there was a constant increase in data reading following the trend line. 
											From the graph, we can conclude that, the data reading showed are a postive correlation. A positive correlation is a relationship between two variables in which both variables move in the same direction. 
											Therefore, when one variable increases as the other variable increases, or one variable decreases while the other decreases. In conclusion, user times in bed are correlated with minute sleep, which gives, the higher the time in bed, the longer the minute sleep.
										</p><br />

										<h5>> TOTAL & AVERAGE VALUES FOR TIME IN BED, MINUTE SLEEP</h5>

										<p>
											Next, let create another correlation but this time between total steps and distance with calories burnt. Created figure are shown below:: 
										</p>
									
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/2.2.jpg" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.23: Sleep Trends visualization (2)</figcaption><br />										
										</section>

										<p>
											The above graph showed that there are four trends created within one frame separated with two different colour, blue and orange. Which for the first part, in the blue colour, there is a total minute sleep sort by weekday, and another one is average minute sleep sort by weekday. While for the scond part, 
											which in orange colour, there is a total time in bed sort by weekday, and the other one is average time in bed sort by weekday. From the observation, since both minute sleep and total time in bed have a positive correlation, we can clearly see that, for both topic, it has an identical data reading on 'Total' 
											and 'Average' summarization. From the bar reading itself, for 'Total' summarization, the highest values for minute asleep and total time in bed is on wednesday, while for 'Average' data summarization, amount of user are highest on Sunday.
										</p><br />

										<h5>> CATEGORIZE USER BY ACTIVE, MODERATE AND LIGHT</h5>

										<p>
											Now, let's create another visualization on the user which we will categorize them by their activeness when using the smart device. But first before we start, we need to manipulate and tranform our existing data. But, since there is already an explaination and steps on how we tranformed the data we want and all the steps on tranforming the data are identical with previous example,
											so there is no other explaination provided in this part. For this part we will use sleep_day dataset. Below shows created pie chart for this part: 
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/2.3.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.24: Sleep Trends visualization (3)</figcaption><br />										
										</section>

										<p>
											For your information, from this data set, there are only 24 amount of user out of total 33 people, involved to recorded their data on their sleeping behaviour. So, in each of categories above, there are only 24 total amount of unique id participated, used to contruct each of categorical structure shown above. Below shows list of id recorded in sleep_day dataset:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/sleep_id_count.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.25: Total user involved in <i>cleaned_day_sleep</i></figcaption><br />										
										</section>
										<p>
											Now, let's explain the chart. From the pie chart above, we can see that, it is splited with three colours, blue, red and orange. Each of the colour are assigned for each catagories we created previously, blue for active user, red for moderate user and orange for light or least active user. From our initial observation, we can see that active segment are the highest among others, followed by light in second and then moderate the lowest. 
											In conclusion, among 24 total amount of users in this data set, half of them are actively record their the with total population of 50%, followed by lighly-active user with 37.50% of total user and lastly, 12.50 % for moderately-active user. 
											
										</p><br />
												
									</ul>


									<h4><li> HEARTRATE TRENDS </li></h4><br />

									<ul>
										
										<p>
											The main purposes during visualization phase is to explore, obtain some interesting trends for the data and the most important things is to answer the objectives for our analysis. 
											Every data column in every dataset are comparable to each other, using row (x) and column (y) shelves structure in Tableau.
											For the third part of our visualization, cleaned heartrate data set are used as shown below:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/heartrate_glimpse.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.26: <i>cleaned_haertrate</i> dataset</figcaption><br />										
										</section>

										<p>
											For your information, in this data set, there are only 14 total amount of user out of 33 people, involved to recorded their data on their heartrate readings. Below shows list of id recorded in heartrate dataset:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/heartrate_id_count.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.27: Total user involved in <i>cleaned_haertrate</i> </figcaption><br />										
										</section>

										<h5>> COMPARISON BETWEEN ACTIVE, MODERATE AND LIGHT USER TRENDS</h5>

										<p>
											 To start our first visualization, We can create a comparison between active, moderately-active and lightly-active user trend on the topic. The graph created shown below:
											
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/3.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.28: Heartrate Trends visualization (1a)</figcaption><br />										
										</section>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/3.2.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.29: Heartrate Trends visualization (1b)</figcaption><br />											
										</section>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/3.3.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.30: Heartrate Trends visualization (1c)</figcaption><br />											
										</section>

										<p>
											The figure above shows, there are a visualization created separated with three id by colour, blue, red and orange, which to used compared each of them between active, moderately-active and lightly-active user using smart device to measure heartrate.
											For the first id, which in red colour, we can see that, the data reading are slightly the most consistent compared to others in one month of the duration.
											For the second id, which in orange colour, we can see that, the data reading are consistent only for half of the one month duration 
											For the last id, which in blue colour, we can see that, the data reading are the lowest among other which is only recorded for only several of times in one month.
											In conclusion, we can clearly see some of the user usage trends. From what we has observed, we know that id in red are an active user, while orange is slighly an average or moderate, and the last one should be a lighly-active user.
										</p><br />

										
										<h5>> CATEGORIZE USER BY ACTIVE, MODERATE AND LIGHT</h5>

										<p>
											Now, let's create another visualization on the user which we will categorize them by their activeness when using the smart device. But first before we start, we need to manipulate and tranform our existing data. But, since there is already an explaination and steps on how we tranformed the data we want and all the steps on tranforming the data are identical with previous example,
											so there is no other explaination provided in this part. For this part we will use heartrate dataset. Below shows created pie chart for this part: 
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/3.4.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.31: Heartrate Trends visualization (2)</figcaption><br />											
										</section>

										<p>
											Now, let's explain the chart. From the pie chart above, we can see that, it is splited with three colours, blue, red and orange. Each of the colour are assigned for each catagories we created previously, blue for active user, red for moderate user and orange for light or least active user. From our initial observation, we can see that active and moderately-active segment are the highest and sharing the total population, followed by lighty-active in the lowest. 
											In conclusion, among 14 total amount of users in this data set, 42.86% of them are actively used the device to measure heartrate, followed by another 42.86% of total user are moderately-active user and for the lowest, lightly-active user stand with 14.26% total population. 
											
										</p><br />

									</ul>

									<h4><li> MEASURING WEIGHT DATA TRENDS </li></h4><br />

									<ul>
										
										<p>
											The main purposes during visualization phase is to explore, obtain some interesting trends for the data and the most important things is to answer the objectives for our analysis. 
											Every data column in every dataset are comparable to each other, using row (x) and column (y) shelves structure in Tableau.
											For the third part of our visualization, cleaned_weight_info data set are used as shown below:
										</p>
										<section id="one" class="spotlights" >										
											<img src="images/project2_image/weight_glimpse.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.32: <i>cleaned_weight</i> dataset</figcaption><br />										
										</section>

										<p>
											From what we can see from the data set above, there is a null values within the data set in fat column. The 'NA' values is automatically created when there is no input or data uploaded or automaticallly recorded into the smart device user. We can concluded that, most of the user can be considered as not very likely 
											to inputting fat information into the data.
										</p>

										<p>
											For your information, in this data set, there are only 8 total amount of user out of 33 people, involved to recorded their data involving their weight records. Below shows list of id recorded in heartrate dataset:
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/weight_id_count.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.33: Total user involved in <i>cleaned_weight</i> </figcaption><br />										
										</section>

										<h5>> EACH OF USER ACTIVENESS TRENDS</h5>

										<p>
											To start our first visualization, We can create a comparison between each of user activeness, on measuring and recording their weight. The graph created shown below:
											
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/4.1.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.34: Weight Trends visualization (1)</figcaption><br />										
										</section>
									

										<p>
											The figure above shows, a visualization created, separated with eight colour, which used to differ each of the user by id. Each of lines in the graph above tell us about the user activeness when using the smart device to measure their weight and BMI.
											From the visualized data, there are several data trends in a consistent straight line for one month, 
											and there also, several other trends that only created in short amount of duration, creating only a short straight lines and even a dot.
											From the statement, we can clearly know, which data trends can be considered active and not very active, which can be concluded that, the longer the lines, the more active the user.
											
										</p><br />

										
										<h5>> CATEGORIZE USER BY ACTIVE, MODERATE AND LIGHT</h5>

										<p>
											Now, let's create another visualization on the user which we will categorize them by their activeness when using the smart device. But first before we start, we need to manipulate and tranform our existing data. But, since there is already an explaination and steps on how we tranformed the data we want and all the steps on tranforming the data are identical with previous example,
											so there is no other explaination provided in this part. For this part we will use cleaned_weight_info dataset. Below shows created pie chart for this part: 
										</p>

										<section id="one" class="spotlights" >										
											<img src="images/project2_image/4.2.JPG" alt="" data-position="center center" style="width:100%" />
											<figcaption>Figure 4.35: Weight Trends visualization (2)</figcaption><br />										
										</section>

										<p>
											Now, let's explain the chart. From the pie chart above, we can see that, it is splited with three colours, blue, red and orange. Each of the colour are assigned for each catagories we created previously, blue for active user, red for moderate user and orange for light or least active user. From our initial observation, we can see that lightly-active user are the highest in total population, followed by very active segment and moderately-active the lowest. 
											In conclusion, among 8 total amount of users in this data set, only 25% of them are actively used the device to measure and recorded their weight, followed by another 0% of total user are moderately-active user and the highest population, the lightly-active user stand with 75% total population. 
											
										</p><br />
												
									</ul>



								</div>
							</section>


							<!-- Share -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Phase 5: Share</h2>
									</header>
									<p>The purpose of this step is to share the results with the stakeholders. It involves creating visualization 
										and building presentations or reports that summarize the findings of the analysis. It also leads into the 
										final step of the process (Act) by sharing recommendation based on the findings.
									</p>
								</div>
							</section>


							<!-- Act -->
							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>Phase 6: Act</h2>
									</header>
									<p>
										The objective of this step is to share recommendation with the stakeholders and let them choose what next steps to take.
									</p>

										<ul>
											<li>Obtain more data. The objective of this analysis was to identify how each of user in every data set used their smart device service differently. 
												Unfortunately, the data available is insufficient to effectively answer the question asked. Some minor insights were gleaned, but nothing concrete, 
												and nothing particularly significant. There are to recommendations for additional data. First, get data that can tie a given ride to a given user - 
												that could be a user id or a credit card used. This would allow finer analysis to see how many casual rides are one-off rides, rides performed over 
												a few days, or rides performed by a user that frequently uses the service. This information could be used to identify which riders are residents 
												and which are tourists. Since tourists aren't going to purchase a membership, analyzing their patterns is not helpful. Second, send out a survey 
												to casual riders to garner some basic information such as how frequently the use the service</li><br />
											

											<li>Refine the current data. There are several shortcomings of the data as it exists now. First, the member_casual tag should be expanded. There are 
												effectively 3 types of riders - annual members, single-pass casual, and all-day pass casual. The distinction between the two casual types is missing. 
												Having this would allow further analysis. Additionally, there should be a tag that is used when an employee takes a bike to perform an inspection or repair. 
												Second, there should be a flag for when a user checks out a bike and then marks it damaged. This would help identify how many rides with unusually short 
												duration are a result of damaged bikes, as well as allowing a comparison to see whether casual or member users report bikes as damaged more. Furthermore, 
												what happens to a ride record when a bike is stolen or lost. Are these removed, or are they some of the records where the ride lasted days or weeks? 
												There should be a flag for this. Lastly, there are stations that have multiple names or ids. This causes a major data integrity issue becasue it is 
												unclear what certain ids or names represent.
											</li><br />
											

											<li>Repeat the analysis process with the changes above to better understand the different behaviours of casual riders and annual members. Making any 
												decisions based off the limited analysis possible with the existing data would be unwise and would likely have poor results.
											</li><br />
										
			
										</ul>
								</div>
							</section>

					
							<!-- original template code here:

							<section id="one">
								<div class="inner">
									<header class="major">
										<h2>The Data</h2>
									</header>
									<p>All information about the data can be found by viewing the dataset used. In summary, Cyclistic is a fictional bike share company based in Chicago. Divvy is a real bike share company based in Chicago. Divvy makes some of their data available for public use. This is the data used for this case study
										The data has been made available by Motivate International Inc. under this <a href="https://ride.divvybikes.com/data-license-agreement">license</a>.
									</p>
								</div>
							</section>
						-->
						<!-- Two 
							<section id="two" class="spotlights">
								<section>
									<a href="generic.html" class="image">
										<img src="images/pic08.jpg" alt="" data-position="center center" />
									</a>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Orci maecenas</h3>
											</header>
											<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis tempus.</p>
											<ul class="actions">
												<li><a href="generic.html" class="button">Learn more</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<a href="generic.html" class="image">
										<img src="images/casestudy1_24hr.JPG" alt="" data-position="top center" />
									</a>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Rhoncus magna</h3>
											</header>
											<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis tempus.</p>
											<ul class="actions">
												<li><a href="generic.html" class="button">Learn more</a></li>
											</ul>
										</div>
									</div>
								</section>
								<section>
									<a href="generic.html" class="image">
										<img src="images/pic10.jpg" alt="" data-position="25% 25%" />
									</a>
									<div class="content">
										<div class="inner">
											<header class="major">
												<h3>Sed nunc ligula</h3>
											</header>
											<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis magna sed nunc rhoncus condimentum sem. In efficitur ligula tate urna. Maecenas massa sed magna lacinia magna pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis tempus.</p>
											<ul class="actions">
												<li><a href="generic.html" class="button">Learn more</a></li>
											</ul>
										</div>
									</div>
								</section>
							</section>
	                    -->
						<!-- Three 
							<section id="three">
								<div class="inner">
									<header class="major">
										<h2>Massa libero</h2>
									</header>
									<p>Nullam et orci eu lorem consequat tincidunt vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus pharetra. Pellentesque condimentum sem. In efficitur ligula tate urna. Maecenas laoreet massa vel lacinia pellentesque lorem ipsum dolor. Nullam et orci eu lorem consequat tincidunt. Vivamus et sagittis libero. Mauris aliquet magna magna sed nunc rhoncus amet pharetra et feugiat tempus.</p>
									<ul class="actions">
										<li><a href="generic.html" class="button next">Get Started</a></li>
									</ul>
								</div>
							</section>
						-->
					</div>
							



				<!-- Contact 
					<section id="contact">
						<div class="inner">
							<section>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="6"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Clear" /></li>
									</ul>
								</form>
							</section>
							<section class="split">
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-envelope"></span>
										<h3>Email</h3>
										<a href="#">information@untitled.tld</a>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-phone"></span>
										<h3>Phone</h3>
										<span>(000) 000-0000 x12387</span>
									</div>
								</section>
								<section>
									<div class="contact-method">
										<span class="icon solid alt fa-home"></span>
										<h3>Address</h3>
										<span>1234 Somewhere Road #5432<br />
										Nashville, TN 00000<br />
										United States of America</span>
									</div>
								</section>
							</section>
						</div>
					</section>
				-->

				<!-- Footer 
					<footer id="footer">
						<div class="inner">
							<ul class="icons">
								<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>
								<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>
								<li><a href="#" class="icon brands alt fa-instagram"><span class="label">Instagram</span></a></li>
								<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>
								<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Untitled</li><li>Design: <a href="https://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</footer>
				-->

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>